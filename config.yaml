vocab_size: 8258
d_model: 256
seq_len: 256
n_layers: 6
n_heads: 8
d_head: 32
d_ff: 1024

batch_size: 32

data:
  tokenized_tensors: data/tokenized_docs.pt